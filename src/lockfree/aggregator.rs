//! Offline analysis tool for aggregating lock-free multi-threaded binary data.
//!
//! This module processes the binary files generated by thread-local trackers
//! and provides comprehensive analysis across all threads.

use crate::lockfree::tracker::{Event, FrequencyData};
use crate::lockfree::analysis::{AllocationEvent, EventType, InteractionType};
use postcard;
// Removed unused serde imports
use std::collections::HashMap;
use std::path::Path;

use crate::lockfree::analysis::{
    LockfreeAnalysis, ThreadStats, ThreadInteraction, MemoryPeak, 
    PerformanceBottleneck, BottleneckType
};

/// Lock-free multi-threaded data aggregator
pub struct LockfreeAggregator {
    output_dir: std::path::PathBuf,
}

impl LockfreeAggregator {
    pub fn new(output_dir: std::path::PathBuf) -> Self {
        Self { output_dir }
    }

    /// Discover and parse all thread binary files
    pub fn aggregate_all_threads(&self) -> Result<LockfreeAnalysis, Box<dyn std::error::Error>> {
        let mut thread_stats = HashMap::new();
        
        // Discover all thread files
        let thread_files = self.discover_thread_files()?;
        
        for (thread_id, event_file, freq_file) in thread_files {
            let events = self.parse_event_file(&event_file)?;
            let frequencies = self.parse_frequency_file(&freq_file)?;
            
            let stats = self.analyze_thread_data(thread_id, events, frequencies)?;
            thread_stats.insert(thread_id, stats);
        }

        // Perform cross-thread analysis
        let hottest_call_stacks = self.find_hottest_call_stacks(&thread_stats);
        let thread_interactions = self.analyze_thread_interactions(&thread_stats);
        let memory_peaks = self.find_memory_peaks(&thread_stats);
        let performance_bottlenecks = self.detect_performance_bottlenecks(&thread_stats);

        let mut analysis = LockfreeAnalysis::new();
        analysis.thread_stats = thread_stats;
        analysis.hottest_call_stacks = hottest_call_stacks.into_iter()
            .map(|(hash, freq, size)| crate::lockfree::analysis::HotCallStack {
                call_stack_hash: hash,
                total_frequency: freq,
                total_size: size,
                impact_score: freq * size as u64,
                threads: Vec::new(), // Could be populated from thread_stats
            })
            .collect();
        analysis.thread_interactions = thread_interactions;
        analysis.memory_peaks = memory_peaks;
        analysis.performance_bottlenecks = performance_bottlenecks;

        // IMPORTANT: Calculate summary statistics from thread data
        analysis.calculate_summary(std::time::Instant::now());

        Ok(analysis)
    }

    /// Discover all thread binary files in output directory
    fn discover_thread_files(&self) -> Result<Vec<(u64, std::path::PathBuf, std::path::PathBuf)>, Box<dyn std::error::Error>> {
        let mut files = Vec::new();
        
        if !self.output_dir.exists() {
            return Ok(files);
        }

        for entry in std::fs::read_dir(&self.output_dir)? {
            let entry = entry?;
            let path = entry.path();
            
            if let Some(file_name) = path.file_name().and_then(|n| n.to_str()) {
                if file_name.starts_with("memscope_thread_") && file_name.ends_with(".bin") {
                    // Extract thread ID from filename
                    let thread_id_str = file_name
                        .strip_prefix("memscope_thread_")
                        .and_then(|s| s.strip_suffix(".bin"))
                        .ok_or("Invalid thread file name format")?;
                    
                    let thread_id: u64 = thread_id_str.parse()?;
                    
                    let freq_file = path.with_extension("freq");
                    if freq_file.exists() {
                        files.push((thread_id, path, freq_file));
                    }
                }
            }
        }
        
        Ok(files)
    }

    /// Parse event file and return all events
    fn parse_event_file(&self, file_path: &Path) -> Result<Vec<Event>, Box<dyn std::error::Error>> {
        let file_content = std::fs::read(file_path)?;
        let mut events = Vec::new();
        let mut offset = 0;

        // Read length-prefixed chunks
        while offset + 4 <= file_content.len() {
            // Read length (4 bytes, little endian)
            let length_bytes = &file_content[offset..offset + 4];
            let length = u32::from_le_bytes([length_bytes[0], length_bytes[1], length_bytes[2], length_bytes[3]]) as usize;
            offset += 4;

            if offset + length > file_content.len() {
                break; // Incomplete chunk
            }

            // Deserialize events chunk
            let chunk_data = &file_content[offset..offset + length];
            let chunk_events: Vec<Event> = postcard::from_bytes(chunk_data)?;
            events.extend(chunk_events);
            offset += length;
        }

        Ok(events)
    }

    /// Parse frequency file
    fn parse_frequency_file(&self, file_path: &Path) -> Result<Vec<FrequencyData>, Box<dyn std::error::Error>> {
        let file_content = std::fs::read(file_path)?;
        let frequencies: Vec<FrequencyData> = postcard::from_bytes(&file_content)?;
        Ok(frequencies)
    }

    /// Analyze single thread data and convert Event to AllocationEvent
    fn analyze_thread_data(&self, thread_id: u64, events: Vec<Event>, frequencies: Vec<FrequencyData>) -> Result<ThreadStats, Box<dyn std::error::Error>> {
        let mut allocations = 0u64;
        let mut deallocations = 0u64;
        let mut current_memory = 0usize;
        let mut peak_memory = 0usize;
        let mut total_allocated = 0usize;
        let mut allocation_sizes = Vec::new();

        // Process events chronologically
        let mut sorted_events = events;
        sorted_events.sort_by_key(|e| e.timestamp);

        for event in &sorted_events {
            match event.event_type {
                EventType::Allocation => {
                    allocations += 1;
                    current_memory += event.size;
                    total_allocated += event.size;
                    allocation_sizes.push(event.size);
                    peak_memory = peak_memory.max(current_memory);
                }
                EventType::Deallocation => {
                    deallocations += 1;
                    // Note: We don't track exact deallocation sizes in current implementation
                    // This could be enhanced by tracking allocation->deallocation mapping
                }
            }
        }

        let avg_allocation_size = if !allocation_sizes.is_empty() {
            allocation_sizes.iter().sum::<usize>() as f64 / allocation_sizes.len() as f64
        } else {
            0.0
        };

        // Build frequency map from frequency data
        let allocation_frequency: HashMap<u64, u64> = frequencies
            .into_iter()
            .map(|f| (f.call_stack_hash, f.frequency))
            .collect();

        // Convert Event to AllocationEvent for analysis compatibility
        let timeline: Vec<AllocationEvent> = sorted_events.into_iter().map(|event| {
            AllocationEvent {
                timestamp: event.timestamp,
                ptr: event.ptr,
                size: event.size,
                call_stack_hash: event.call_stack_hash,
                event_type: event.event_type,
                thread_id: event.thread_id,
            }
        }).collect();

        Ok(ThreadStats {
            thread_id,
            total_allocations: allocations,
            total_deallocations: deallocations,
            peak_memory,
            total_allocated,
            allocation_frequency,
            avg_allocation_size,
            timeline,
        })
    }

    /// Find hottest call stacks across all threads
    fn find_hottest_call_stacks(&self, thread_stats: &HashMap<u64, ThreadStats>) -> Vec<(u64, u64, usize)> {
        let mut call_stack_totals: HashMap<u64, (u64, usize)> = HashMap::new();

        for stats in thread_stats.values() {
            for (&hash, &frequency) in &stats.allocation_frequency {
                let entry = call_stack_totals.entry(hash).or_insert((0, 0));
                entry.0 += frequency;
                // Estimate total size (this could be more accurate with better tracking)
                entry.1 += (stats.avg_allocation_size as usize) * frequency as usize;
            }
        }

        let mut hottest: Vec<(u64, u64, usize)> = call_stack_totals
            .into_iter()
            .map(|(hash, (freq, size))| (hash, freq, size))
            .collect();

        // Sort by frequency * size to find most impactful call stacks
        hottest.sort_by(|a, b| (b.1 * b.2 as u64).cmp(&(a.1 * a.2 as u64)));
        hottest.truncate(50); // Top 50 hottest call stacks

        hottest
    }

    /// Analyze interactions between threads
    fn analyze_thread_interactions(&self, thread_stats: &HashMap<u64, ThreadStats>) -> Vec<ThreadInteraction> {
        let mut interactions = Vec::new();

        // Simple heuristic: threads that allocate in similar memory regions might be interacting
        let thread_ids: Vec<u64> = thread_stats.keys().copied().collect();

        for i in 0..thread_ids.len() {
            for j in i + 1..thread_ids.len() {
                let thread_a = thread_ids[i];
                let thread_b = thread_ids[j];

                let stats_a = &thread_stats[&thread_a];
                let stats_b = &thread_stats[&thread_b];

                // Check for shared allocation patterns (simplified)
                let mut shared_regions = Vec::new();
                let mut interaction_count = 0u64;

                // Find common call stack patterns (indicating similar allocation patterns)
                for (&hash_a, &freq_a) in &stats_a.allocation_frequency {
                    if let Some(&freq_b) = stats_b.allocation_frequency.get(&hash_a) {
                        interaction_count += freq_a.min(freq_b);
                        // Use call stack hash as proxy for shared pattern
                        shared_regions.push(hash_a);
                    }
                }

                if interaction_count > 0 {
                    interactions.push(ThreadInteraction {
                        thread_a,
                        thread_b,
                        shared_patterns: shared_regions,
                        interaction_strength: interaction_count,
                        interaction_type: InteractionType::SimilarPatterns,
                    });
                }
            }
        }

        // Sort by interaction strength
        interactions.sort_by(|a, b| b.interaction_strength.cmp(&a.interaction_strength));
        interactions
    }

    /// Find memory usage peaks across all threads
    fn find_memory_peaks(&self, thread_stats: &HashMap<u64, ThreadStats>) -> Vec<MemoryPeak> {
        let mut peaks = Vec::new();

        for stats in thread_stats.values() {
            let mut current_memory = 0usize;
            let mut current_allocations = 0u64;

            for event in &stats.timeline {
                match event.event_type {
                    EventType::Allocation => {
                        current_memory += event.size;
                        current_allocations += 1;

                        // Record peak if it's significant
                        if current_memory > 1024 * 1024 { // > 1MB
                            peaks.push(MemoryPeak {
                                timestamp: event.timestamp,
                                thread_id: stats.thread_id,
                                memory_usage: current_memory,
                                active_allocations: current_allocations,
                                triggering_call_stack: event.call_stack_hash,
                            });
                        }
                    }
                    EventType::Deallocation => {
                        current_allocations = current_allocations.saturating_sub(1);
                        // Note: memory tracking for deallocation would need size info
                    }
                }
            }
        }

        // Sort by memory usage
        peaks.sort_by(|a, b| b.memory_usage.cmp(&a.memory_usage));
        peaks.truncate(100); // Top 100 peaks

        peaks
    }

    /// Detect performance bottlenecks
    fn detect_performance_bottlenecks(&self, thread_stats: &HashMap<u64, ThreadStats>) -> Vec<PerformanceBottleneck> {
        let mut bottlenecks = Vec::new();

        for stats in thread_stats.values() {
            // Detect high-frequency small allocations
            for (&hash, &frequency) in &stats.allocation_frequency {
                if frequency > 1000 && stats.avg_allocation_size < 1024.0 {
                    bottlenecks.push(PerformanceBottleneck {
                        bottleneck_type: BottleneckType::HighFrequencySmallAllocation,
                        thread_id: stats.thread_id,
                        call_stack_hash: hash,
                        severity: (frequency as f64 / 10000.0).min(1.0),
                        description: format!("High frequency ({}) small allocations (avg {}B) in thread {}", 
                                           frequency, stats.avg_allocation_size as usize, stats.thread_id),
                        suggestion: "Consider using memory pools or batch allocation strategies".to_string(),
                    });
                }
            }

            // Detect potential memory leaks
            if stats.total_deallocations == 0 && stats.total_allocations > 100 {
                bottlenecks.push(PerformanceBottleneck {
                    bottleneck_type: BottleneckType::MemoryLeak,
                    thread_id: stats.thread_id,
                    call_stack_hash: 0, // General thread issue
                    severity: 0.8,
                    description: format!("Potential memory leak: {} allocations, 0 deallocations in thread {}", 
                                       stats.total_allocations, stats.thread_id),
                    suggestion: "Review deallocation logic and consider using RAII patterns".to_string(),
                });
            }

            // Detect large allocation spikes
            if stats.peak_memory > 100 * 1024 * 1024 { // > 100MB
                bottlenecks.push(PerformanceBottleneck {
                    bottleneck_type: BottleneckType::LargeAllocationSpike,
                    thread_id: stats.thread_id,
                    call_stack_hash: 0,
                    severity: (stats.peak_memory as f64 / (1024.0 * 1024.0 * 1024.0)).min(1.0), // Severity based on GB
                    description: format!("Large memory spike: {}MB peak in thread {}", 
                                       stats.peak_memory / (1024 * 1024), stats.thread_id),
                    suggestion: "Consider streaming or chunked processing for large data sets".to_string(),
                });
            }
        }

        // Sort by severity
        bottlenecks.sort_by(|a, b| b.severity.partial_cmp(&a.severity).unwrap_or(std::cmp::Ordering::Equal));
        bottlenecks
    }

    /// Export aggregated analysis to JSON
    pub fn export_analysis(&self, analysis: &LockfreeAnalysis, output_path: &Path) -> Result<(), Box<dyn std::error::Error>> {
        let json_content = serde_json::to_string_pretty(analysis)?;
        std::fs::write(output_path, json_content)?;
        Ok(())
    }

    /// Generate comprehensive HTML report
    pub fn generate_html_report(&self, analysis: &LockfreeAnalysis, output_path: &Path) -> Result<(), Box<dyn std::error::Error>> {
        let html_content = self.build_html_report(analysis)?;
        std::fs::write(output_path, html_content)?;
        Ok(())
    }

    fn build_html_report(&self, analysis: &LockfreeAnalysis) -> Result<String, Box<dyn std::error::Error>> {
        let mut html = String::new();
        
        html.push_str("<!DOCTYPE html>\n<html>\n<head>\n");
        html.push_str("<title>Multi-threaded Memory Analysis Report</title>\n");
        html.push_str("<style>\n");
        html.push_str("body { font-family: Arial, sans-serif; margin: 20px; }\n");
        html.push_str(".section { margin-bottom: 30px; }\n");
        html.push_str(".thread-stats { border: 1px solid #ccc; padding: 15px; margin: 10px; }\n");
        html.push_str(".bottleneck { background-color: #ffe6e6; padding: 10px; margin: 5px; border-left: 4px solid red; }\n");
        html.push_str(".interaction { background-color: #e6f3ff; padding: 10px; margin: 5px; border-left: 4px solid blue; }\n");
        html.push_str("table { border-collapse: collapse; width: 100%; }\n");
        html.push_str("th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }\n");
        html.push_str("th { background-color: #f2f2f2; }\n");
        html.push_str("</style>\n</head>\n<body>\n");

        html.push_str("<h1>Multi-threaded Memory Analysis Report</h1>\n");

        // Thread Statistics Section
        html.push_str("<div class='section'>\n<h2>Thread Statistics</h2>\n");
        for (thread_id, stats) in &analysis.thread_stats {
            html.push_str(&format!("<div class='thread-stats'>\n"));
            html.push_str(&format!("<h3>Thread {}</h3>\n", thread_id));
            html.push_str(&format!("<p><strong>Total Allocations:</strong> {}</p>\n", stats.total_allocations));
            html.push_str(&format!("<p><strong>Total Deallocations:</strong> {}</p>\n", stats.total_deallocations));
            html.push_str(&format!("<p><strong>Peak Memory:</strong> {} bytes ({:.2} MB)</p>\n", 
                                 stats.peak_memory, stats.peak_memory as f64 / (1024.0 * 1024.0)));
            html.push_str(&format!("<p><strong>Total Allocated:</strong> {} bytes ({:.2} MB)</p>\n", 
                                 stats.total_allocated, stats.total_allocated as f64 / (1024.0 * 1024.0)));
            html.push_str(&format!("<p><strong>Average Allocation Size:</strong> {:.2} bytes</p>\n", stats.avg_allocation_size));
            html.push_str("</div>\n");
        }
        html.push_str("</div>\n");

        // Performance Bottlenecks Section
        html.push_str("<div class='section'>\n<h2>Performance Bottlenecks</h2>\n");
        for bottleneck in &analysis.performance_bottlenecks {
            html.push_str("<div class='bottleneck'>\n");
            html.push_str(&format!("<strong>{:?}</strong> (Severity: {:.2})<br>\n", 
                                 bottleneck.bottleneck_type, bottleneck.severity));
            html.push_str(&format!("{}<br>\n", bottleneck.description));
            html.push_str(&format!("Thread: {}, Call Stack Hash: 0x{:x}\n", 
                                 bottleneck.thread_id, bottleneck.call_stack_hash));
            html.push_str("</div>\n");
        }
        html.push_str("</div>\n");

        // Thread Interactions Section
        html.push_str("<div class='section'>\n<h2>Thread Interactions</h2>\n");
        for interaction in &analysis.thread_interactions {
            html.push_str("<div class='interaction'>\n");
            html.push_str(&format!("Thread {} ↔ Thread {} (Strength: {})<br>\n", 
                                 interaction.thread_a, interaction.thread_b, interaction.interaction_strength));
            html.push_str(&format!("Shared Patterns: {}<br>\n", interaction.shared_patterns.len()));
            html.push_str("</div>\n");
        }
        html.push_str("</div>\n");

        // Hottest Call Stacks Section
        html.push_str("<div class='section'>\n<h2>Hottest Call Stacks</h2>\n");
        html.push_str("<table>\n<tr><th>Rank</th><th>Call Stack Hash</th><th>Frequency</th><th>Total Size (bytes)</th><th>Impact Score</th></tr>\n");
        for (i, hot_stack) in analysis.hottest_call_stacks.iter().enumerate() {
            html.push_str(&format!("<tr><td>{}</td><td>0x{:x}</td><td>{}</td><td>{}</td><td>{}</td></tr>\n", 
                                 i + 1, hot_stack.call_stack_hash, hot_stack.total_frequency, 
                                 hot_stack.total_size, hot_stack.impact_score));
        }
        html.push_str("</table>\n</div>\n");

        html.push_str("</body>\n</html>");
        Ok(html)
    }
}