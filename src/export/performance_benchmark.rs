//! Performance benchmark module
//!
//! This module provides comprehensive performance benchmarking functionality
//! to compare export performance before and after optimization,
//! particularly using complex_lifecycle_showcase.rs as the benchmark test case.

use crate::core::tracker::get_global_tracker;
use crate::core::types::{TrackingResult, AllocationInfo};
use crate::export::fast_export_coordinator::{FastExportCoordinator, FastExportConfig, CompleteExportStats};
use crate::export::optimized_json_export::OptimizedExportOptions;
use std::collections::HashMap;
use std::fs;
use std::path::{Path, PathBuf};
use std::process::Command;
use std::time::{Duration, Instant};
use serde::{Deserialize, Serialize};

/// Benchmark configuration
#[derive(Debug, Clone)]
pub struct BenchmarkConfig {
    /// Number of test runs
    pub test_runs: usize,
    /// Output directory
    pub output_dir: PathBuf,
    /// æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿—
    pub verbose: bool,
    /// æ˜¯å¦éªŒè¯è¾“å‡ºä¸€è‡´æ€§
    pub verify_consistency: bool,
    /// æ˜¯å¦ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    pub generate_detailed_report: bool,
}

impl Default for BenchmarkConfig {
    fn default() -> Self {
        Self {
            test_runs: 5,
            output_dir: PathBuf::from("benchmark_results"),
            verbose: true,
            verify_consistency: true,
            generate_detailed_report: true,
        }
    }
}

/// å•æ¬¡æµ‹è¯•ç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BenchmarkResult {
    /// æµ‹è¯•åç§°
    pub test_name: String,
    /// å¯¼å‡ºæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    pub export_time_ms: u64,
    /// å†…å­˜ä½¿ç”¨å³°å€¼ï¼ˆå­—èŠ‚ï¼‰
    pub peak_memory_bytes: usize,
    /// è¾“å‡ºæ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    pub output_file_size: usize,
    /// å¤„ç†çš„åˆ†é…æ•°é‡
    pub allocations_processed: usize,
    /// ååé‡ï¼ˆåˆ†é…/ç§’ï¼‰
    pub throughput_allocations_per_sec: f64,
    /// å†™å…¥é€Ÿåº¦ï¼ˆMB/sï¼‰
    pub write_speed_mbps: f64,
    /// æ˜¯å¦æˆåŠŸ
    pub success: bool,
    /// é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    pub error_message: Option<String>,
}/// åŸºå‡†æµ‹è¯•æ¯”
è¾ƒç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BenchmarkComparison {
    /// ä¼ ç»Ÿå¯¼å‡ºç»“æœ
    pub traditional_results: Vec<BenchmarkResult>,
    /// å¿«é€Ÿå¯¼å‡ºç»“æœ
    pub fast_results: Vec<BenchmarkResult>,
    /// æ€§èƒ½æå‡ç»Ÿè®¡
    pub performance_improvement: PerformanceImprovement,
    /// æµ‹è¯•é…ç½®
    pub config: BenchmarkConfig,
    /// æµ‹è¯•æ—¶é—´æˆ³
    pub timestamp: String,
}

/// æ€§èƒ½æå‡ç»Ÿè®¡
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceImprovement {
    /// å¹³å‡å¯¼å‡ºæ—¶é—´æ”¹å–„ï¼ˆç™¾åˆ†æ¯”ï¼‰
    pub avg_time_improvement_percent: f64,
    /// å¹³å‡å†…å­˜ä½¿ç”¨æ”¹å–„ï¼ˆç™¾åˆ†æ¯”ï¼‰
    pub avg_memory_improvement_percent: f64,
    /// å¹³å‡ååé‡æå‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
    pub avg_throughput_improvement_percent: f64,
    /// å¹³å‡å†™å…¥é€Ÿåº¦æå‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
    pub avg_write_speed_improvement_percent: f64,
    /// æœ€ä½³æ—¶é—´æ”¹å–„ï¼ˆç™¾åˆ†æ¯”ï¼‰
    pub best_time_improvement_percent: f64,
    /// æœ€å·®æ—¶é—´æ”¹å–„ï¼ˆç™¾åˆ†æ¯”ï¼‰
    pub worst_time_improvement_percent: f64,
    /// ä¸€è‡´æ€§è¯„åˆ†ï¼ˆ0-100ï¼‰
    pub consistency_score: f64,
}

/// æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨
pub struct PerformanceBenchmark {
    /// é…ç½®
    config: BenchmarkConfig,
    /// æµ‹è¯•ç»“æœå†å²
    results_history: Vec<BenchmarkComparison>,
}

impl PerformanceBenchmark {
    /// åˆ›å»ºæ–°çš„æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨
    pub fn new(config: BenchmarkConfig) -> TrackingResult<Self> {
        // åˆ›å»ºè¾“å‡ºç›®å½•
        fs::create_dir_all(&config.output_dir)?;
        
        Ok(Self {
            config,
            results_history: Vec::new(),
        })
    }

    /// è¿è¡Œå®Œæ•´çš„åŸºå‡†æµ‹è¯•
    pub fn run_full_benchmark(&mut self) -> TrackingResult<BenchmarkComparison> {
        println!("ğŸš€ å¼€å§‹æ€§èƒ½åŸºå‡†æµ‹è¯•");
        println!("==================");
        println!("æµ‹è¯•é…ç½®:");
        println!("  - è¿è¡Œæ¬¡æ•°: {}", self.config.test_runs);
        println!("  - è¾“å‡ºç›®å½•: {}", self.config.output_dir.display());
        println!("  - éªŒè¯ä¸€è‡´æ€§: {}", self.config.verify_consistency);
        println!();

        // è¿è¡Œ complex_lifecycle_showcase ç”Ÿæˆæµ‹è¯•æ•°æ®
        self.prepare_test_data()?;

        // è¿è¡Œä¼ ç»Ÿå¯¼å‡ºæµ‹è¯•
        println!("ğŸ“Š æµ‹è¯•ä¼ ç»Ÿå¯¼å‡ºç³»ç»Ÿ...");
        let traditional_results = self.run_traditional_export_tests()?;

        // è¿è¡Œå¿«é€Ÿå¯¼å‡ºæµ‹è¯•
        println!("âš¡ æµ‹è¯•å¿«é€Ÿå¯¼å‡ºç³»ç»Ÿ...");
        let fast_results = self.run_fast_export_tests()?;

        // è®¡ç®—æ€§èƒ½æå‡
        let performance_improvement = self.calculate_performance_improvement(&traditional_results, &fast_results);

        // åˆ›å»ºæ¯”è¾ƒç»“æœ
        let comparison = BenchmarkComparison {
            traditional_results,
            fast_results,
            performance_improvement,
            config: self.config.clone(),
            timestamp: chrono::Utc::now().to_rfc3339(),
        };

        // ä¿å­˜ç»“æœ
        self.save_benchmark_results(&comparison)?;

        // ç”ŸæˆæŠ¥å‘Š
        if self.config.generate_detailed_report {
            self.generate_detailed_report(&comparison)?;
        }

        // æ·»åŠ åˆ°å†å²è®°å½•
        self.results_history.push(comparison.clone());

        Ok(comparison)
    }    /// å‡†å¤‡
æµ‹è¯•æ•°æ®
    fn prepare_test_data(&self) -> TrackingResult<()> {
        println!("ğŸ”§ å‡†å¤‡æµ‹è¯•æ•°æ®...");
        
        // è¿è¡Œ complex_lifecycle_showcase ç¤ºä¾‹æ¥ç”Ÿæˆå¤æ‚çš„å†…å­˜åˆ†é…æ¨¡å¼
        let output = Command::new("cargo")
            .args(&["run", "--example", "complex_lifecycle_showcase"])
            .output()
            .map_err(|e| crate::core::types::TrackingError::IoError(e.to_string()))?;

        if !output.status.success() {
            let stderr = String::from_utf8_lossy(&output.stderr);
            return Err(crate::core::types::TrackingError::ExportError(
                format!("Failed to run complex_lifecycle_showcase: {}", stderr)
            ));
        }

        if self.config.verbose {
            println!("âœ… æµ‹è¯•æ•°æ®å‡†å¤‡å®Œæˆ");
        }

        Ok(())
    }

    /// è¿è¡Œä¼ ç»Ÿå¯¼å‡ºæµ‹è¯•
    fn run_traditional_export_tests(&self) -> TrackingResult<Vec<BenchmarkResult>> {
        let mut results = Vec::new();

        for run in 1..=self.config.test_runs {
            if self.config.verbose {
                println!("  è¿è¡Œ {}/{}: ä¼ ç»Ÿå¯¼å‡º", run, self.config.test_runs);
            }

            let result = self.run_single_traditional_test(run)?;
            results.push(result);

            // çŸ­æš‚ä¼‘æ¯ä»¥é¿å…ç³»ç»Ÿè´Ÿè½½å½±å“
            std::thread::sleep(Duration::from_millis(100));
        }

        Ok(results)
    }

    /// è¿è¡Œå¿«é€Ÿå¯¼å‡ºæµ‹è¯•
    fn run_fast_export_tests(&self) -> TrackingResult<Vec<BenchmarkResult>> {
        let mut results = Vec::new();

        for run in 1..=self.config.test_runs {
            if self.config.verbose {
                println!("  è¿è¡Œ {}/{}: å¿«é€Ÿå¯¼å‡º", run, self.config.test_runs);
            }

            let result = self.run_single_fast_test(run)?;
            results.push(result);

            // çŸ­æš‚ä¼‘æ¯ä»¥é¿å…ç³»ç»Ÿè´Ÿè½½å½±å“
            std::thread::sleep(Duration::from_millis(100));
        }

        Ok(results)
    }

    /// è¿è¡Œå•æ¬¡ä¼ ç»Ÿå¯¼å‡ºæµ‹è¯•
    fn run_single_traditional_test(&self, run_number: usize) -> TrackingResult<BenchmarkResult> {
        let start_time = Instant::now();
        let output_path = self.config.output_dir.join(format!("traditional_export_run_{}.json", run_number));

        // è·å–å½“å‰å†…å­˜è·Ÿè¸ªå™¨çŠ¶æ€
        let tracker = get_global_tracker();
        let initial_stats = tracker.get_stats()?;

        // ä½¿ç”¨ä¼ ç»Ÿçš„ä¼˜åŒ–å¯¼å‡ºé€‰é¡¹
        let options = OptimizedExportOptions {
            enable_streaming: true,
            enable_compression: false,
            batch_size: 1000,
            enable_parallel_processing: false, // ä¼ ç»Ÿæ–¹å¼ä¸ä½¿ç”¨å¹¶è¡Œ
            max_file_size_mb: 100,
            output_format: crate::export::optimized_json_export::OutputFormat::Json,
        };

        // æ‰§è¡Œä¼ ç»Ÿå¯¼å‡º
        let export_result = tracker.export_to_json_with_optimized_options(&output_path, options);
        let export_time = start_time.elapsed();

        // è·å–æœ€ç»ˆç»Ÿè®¡
        let final_stats = tracker.get_stats()?;

        // æ£€æŸ¥æ–‡ä»¶å¤§å°
        let output_file_size = if output_path.exists() {
            fs::metadata(&output_path)?.len() as usize
        } else {
            0
        };

        // è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        let allocations_processed = final_stats.total_allocations;
        let throughput = if export_time.as_secs_f64() > 0.0 {
            allocations_processed as f64 / export_time.as_secs_f64()
        } else {
            0.0
        };

        let write_speed_mbps = if export_time.as_secs_f64() > 0.0 && output_file_size > 0 {
            (output_file_size as f64 / 1024.0 / 1024.0) / export_time.as_secs_f64()
        } else {
            0.0
        };

        let result = BenchmarkResult {
            test_name: format!("Traditional Export Run {}", run_number),
            export_time_ms: export_time.as_millis() as u64,
            peak_memory_bytes: final_stats.peak_memory,
            output_file_size,
            allocations_processed,
            throughput_allocations_per_sec: throughput,
            write_speed_mbps,
            success: export_result.is_ok(),
            error_message: export_result.err().map(|e| e.to_string()),
        };

        if self.config.verbose {
            println!("    â±ï¸  æ—¶é—´: {}ms, ğŸ“Š åˆ†é…: {}, ğŸ“ å¤§å°: {:.2}MB", 
                    result.export_time_ms, 
                    result.allocations_processed,
                    result.output_file_size as f64 / 1024.0 / 1024.0);
        }

        Ok(result)
    }