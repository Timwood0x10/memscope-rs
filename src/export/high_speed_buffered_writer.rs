//! é«˜é€Ÿç¼“å†²å†™å…¥å™¨ - å‡å°‘ I/O å¼€é”€çš„é«˜æ€§èƒ½æ–‡ä»¶å†™å…¥
//!
//! è¿™ä¸ªæ¨¡å—å®ç°äº†é«˜é€Ÿç¼“å†²å†™å…¥åŠŸèƒ½ï¼Œä½¿ç”¨å¤§ç¼“å†²åŒºå‡å°‘ç³»ç»Ÿè°ƒç”¨æ¬¡æ•°ï¼Œ
//! å¹¶æä¾›é«˜æ•ˆçš„åˆ†ç‰‡åˆå¹¶é€»è¾‘ï¼Œæ˜¾è‘—æé«˜æ–‡ä»¶å†™å…¥æ€§èƒ½ã€‚

use crate::core::types::{TrackingError, TrackingResult};
use crate::export::parallel_shard_processor::ProcessedShard;
use std::fs::File;
use std::io::{BufWriter, Write};
use std::path::Path;
use std::time::Instant;

/// é«˜é€Ÿç¼“å†²å†™å…¥å™¨é…ç½®
#[derive(Debug, Clone)]
pub struct HighSpeedWriterConfig {
    /// ç¼“å†²åŒºå¤§å°ï¼ˆå­—èŠ‚ï¼‰
    pub buffer_size: usize,
    /// æ˜¯å¦å¯ç”¨æ€§èƒ½ç›‘æ§
    pub enable_monitoring: bool,
    /// é¢„ä¼°æ€»è¾“å‡ºå¤§å°ï¼ˆç”¨äºé¢„åˆ†é…ï¼‰
    pub estimated_total_size: Option<usize>,
    /// æ˜¯å¦ä½¿ç”¨å‹ç¼©å†™å…¥
    pub enable_compression: bool,
    /// å†™å…¥å®Œæˆåæ˜¯å¦ç«‹å³åˆ·æ–°
    pub auto_flush: bool,
}

impl Default for HighSpeedWriterConfig {
    fn default() -> Self {
        Self {
            buffer_size: 2 * 1024 * 1024, // 2MB ç¼“å†²åŒº
            enable_monitoring: true,
            estimated_total_size: None,
            enable_compression: false,
            auto_flush: true,
        }
    }
}

/// å†™å…¥æ€§èƒ½ç»Ÿè®¡
#[derive(Debug, Clone)]
pub struct WritePerformanceStats {
    /// å†™å…¥çš„æ€»å­—èŠ‚æ•°
    pub total_bytes_written: usize,
    /// å†™å…¥çš„åˆ†ç‰‡æ•°é‡
    pub shards_written: usize,
    /// æ€»å†™å…¥æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    pub total_write_time_ms: u64,
    /// å¹³å‡å†™å…¥é€Ÿåº¦ï¼ˆå­—èŠ‚/ç§’ï¼‰
    pub avg_write_speed_bps: f64,
    /// ç¼“å†²åŒºåˆ·æ–°æ¬¡æ•°
    pub flush_count: usize,
    /// é¢„åˆ†é…æ˜¯å¦æœ‰æ•ˆ
    pub preallocation_effective: bool,
    /// å®é™…ç¼“å†²åŒºä½¿ç”¨ç‡
    pub buffer_utilization: f64,
}

/// é«˜é€Ÿç¼“å†²å†™å…¥å™¨
pub struct HighSpeedBufferedWriter {
    /// å†…éƒ¨ç¼“å†²å†™å…¥å™¨
    writer: BufWriter<File>,
    /// é…ç½®
    config: HighSpeedWriterConfig,
    /// å†…éƒ¨ç¼“å†²åŒº
    internal_buffer: Vec<u8>,
    /// ç»Ÿè®¡ä¿¡æ¯
    stats: WritePerformanceStats,
    /// å¼€å§‹æ—¶é—´
    start_time: Instant,
    /// åˆ·æ–°è®¡æ•°
    flush_count: usize,
}

impl HighSpeedBufferedWriter {
    /// åˆ›å»ºæ–°çš„é«˜é€Ÿç¼“å†²å†™å…¥å™¨
    pub fn new<P: AsRef<Path>>(path: P, config: HighSpeedWriterConfig) -> TrackingResult<Self> {
        let file = File::create(path.as_ref())
            .map_err(|e| TrackingError::IoError(format!("åˆ›å»ºæ–‡ä»¶å¤±è´¥: {}", e)))?;

        let writer = BufWriter::with_capacity(config.buffer_size, file);

        // é¢„åˆ†é…å†…éƒ¨ç¼“å†²åŒº
        let initial_capacity = config.estimated_total_size.unwrap_or(1024 * 1024); // é»˜è®¤ 1MB
        let internal_buffer = Vec::with_capacity(initial_capacity);

        let stats = WritePerformanceStats {
            total_bytes_written: 0,
            shards_written: 0,
            total_write_time_ms: 0,
            avg_write_speed_bps: 0.0,
            flush_count: 0,
            preallocation_effective: false,
            buffer_utilization: 0.0,
        };

        Ok(Self {
            writer,
            config,
            internal_buffer,
            stats,
            start_time: Instant::now(),
            flush_count: 0,
        })
    }

    /// å†™å…¥å¤„ç†åçš„åˆ†ç‰‡æ•°æ®
    pub fn write_processed_shards(&mut self, shards: &[ProcessedShard]) -> TrackingResult<WritePerformanceStats> {
        let write_start = Instant::now();

        if self.config.enable_monitoring {
            println!("ğŸ”„ Starting high-speed buffered write for {} shards...", shards.len());
        }

        // é¢„è®¡ç®—æ€»å¤§å°å¹¶é¢„åˆ†é…ç¼“å†²åŒº
        let total_size: usize = shards.iter().map(|s| s.data.len()).sum();
        let estimated_final_size = total_size + 1024; // é¢å¤–ç©ºé—´ç”¨äº JSON ç»“æ„

        // æ£€æŸ¥é¢„åˆ†é…æ˜¯å¦æœ‰æ•ˆ
        self.stats.preallocation_effective = self.internal_buffer.capacity() >= estimated_final_size;
        
        if !self.stats.preallocation_effective {
            self.internal_buffer.reserve(estimated_final_size);
        }

        // æ„å»ºå®Œæ•´çš„ JSON ç»“æ„
        self.build_complete_json(shards)?;

        // ä¸€æ¬¡æ€§å†™å…¥æ–‡ä»¶
        self.writer.write_all(&self.internal_buffer)
            .map_err(|e| TrackingError::IoError(format!("å†™å…¥æ–‡ä»¶å¤±è´¥: {}", e)))?;

        // åˆ·æ–°ç¼“å†²åŒº
        if self.config.auto_flush {
            self.flush()?;
        }

        let write_time = write_start.elapsed();

        // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.stats.total_bytes_written = self.internal_buffer.len();
        self.stats.shards_written = shards.len();
        self.stats.total_write_time_ms = write_time.as_millis() as u64;
        self.stats.avg_write_speed_bps = if write_time.as_secs_f64() > 0.0 {
            self.stats.total_bytes_written as f64 / write_time.as_secs_f64()
        } else {
            0.0
        };
        self.stats.buffer_utilization = if self.internal_buffer.capacity() > 0 {
            self.internal_buffer.len() as f64 / self.internal_buffer.capacity() as f64
        } else {
            0.0
        };

        if self.config.enable_monitoring {
            self.print_write_stats();
        }

        Ok(self.stats.clone())
    }

    /// æ„å»ºå®Œæ•´çš„ JSON ç»“æ„
    fn build_complete_json(&mut self, shards: &[ProcessedShard]) -> TrackingResult<()> {
        // æ¸…ç©ºå†…éƒ¨ç¼“å†²åŒº
        self.internal_buffer.clear();

        // å†™å…¥ JSON å¼€å§‹
        self.internal_buffer.extend_from_slice(b"{\"allocations\":[");

        // åˆå¹¶æ‰€æœ‰åˆ†ç‰‡ï¼Œåªåœ¨åˆ†ç‰‡ä¹‹é—´æ·»åŠ é€—å·
        for (i, shard) in shards.iter().enumerate() {
            if i > 0 {
                self.internal_buffer.extend_from_slice(b",");
            }

            // ç§»é™¤åˆ†ç‰‡çš„ [ å’Œ ]ï¼Œåªä¿ç•™å†…å®¹
            let shard_content = if shard.data.starts_with(b"[") && shard.data.ends_with(b"]") {
                &shard.data[1..shard.data.len()-1]
            } else {
                &shard.data
            };

            self.internal_buffer.extend_from_slice(shard_content);
        }

        // å†™å…¥ JSON ç»“æŸ
        self.internal_buffer.extend_from_slice(b"]}");

        Ok(())
    }

    /// å†™å…¥è‡ªå®šä¹‰ JSON æ•°æ®
    pub fn write_custom_json(&mut self, json_data: &[u8]) -> TrackingResult<WritePerformanceStats> {
        let write_start = Instant::now();

        if self.config.enable_monitoring {
            println!("ğŸ”„ Starting custom JSON data write ({} bytes)...", json_data.len());
        }

        // é¢„åˆ†é…ç¼“å†²åŒº
        if self.internal_buffer.capacity() < json_data.len() {
            self.internal_buffer.reserve(json_data.len());
        }

        // å¤åˆ¶æ•°æ®åˆ°å†…éƒ¨ç¼“å†²åŒº
        self.internal_buffer.clear();
        self.internal_buffer.extend_from_slice(json_data);

        // å†™å…¥æ–‡ä»¶
        self.writer.write_all(&self.internal_buffer)
            .map_err(|e| TrackingError::IoError(format!("å†™å…¥è‡ªå®šä¹‰ JSON å¤±è´¥: {}", e)))?;

        if self.config.auto_flush {
            self.flush()?;
        }

        let write_time = write_start.elapsed();

        // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.stats.total_bytes_written = json_data.len();
        self.stats.shards_written = 1; // è‡ªå®šä¹‰æ•°æ®ç®—ä½œä¸€ä¸ªåˆ†ç‰‡
        self.stats.total_write_time_ms = write_time.as_millis() as u64;
        self.stats.avg_write_speed_bps = if write_time.as_secs_f64() > 0.0 {
            json_data.len() as f64 / write_time.as_secs_f64()
        } else {
            0.0
        };

        if self.config.enable_monitoring {
            self.print_write_stats();
        }

        Ok(self.stats.clone())
    }

    /// å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒº
    pub fn flush(&mut self) -> TrackingResult<()> {
        self.writer.flush()
            .map_err(|e| TrackingError::IoError(format!("åˆ·æ–°ç¼“å†²åŒºå¤±è´¥: {}", e)))?;
        
        self.flush_count += 1;
        self.stats.flush_count = self.flush_count;
        
        Ok(())
    }

    /// å®Œæˆå†™å…¥å¹¶è·å–æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
    pub fn finalize(mut self) -> TrackingResult<WritePerformanceStats> {
        // ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½è¢«å†™å…¥
        self.flush()?;

        // è®¡ç®—æ€»ä½“ç»Ÿè®¡
        let total_time = self.start_time.elapsed();
        self.stats.total_write_time_ms = total_time.as_millis() as u64;

        if self.config.enable_monitoring {
            println!("âœ… High-speed buffered write completed:");
            println!("   Total time: {:?}", total_time);
            self.print_write_stats();
        }

        Ok(self.stats)
    }

    /// è·å–å½“å‰ç»Ÿè®¡ä¿¡æ¯
    pub fn get_stats(&self) -> &WritePerformanceStats {
        &self.stats
    }

    /// è·å–é…ç½®ä¿¡æ¯
    pub fn get_config(&self) -> &HighSpeedWriterConfig {
        &self.config
    }

    /// Print write statistics
    fn print_write_stats(&self) {
        println!("   Bytes written: {} ({:.2} MB)", 
                self.stats.total_bytes_written,
                self.stats.total_bytes_written as f64 / 1024.0 / 1024.0);
        println!("   Shards written: {}", self.stats.shards_written);
        println!("   Write speed: {:.2} MB/s", 
                self.stats.avg_write_speed_bps / 1024.0 / 1024.0);
        println!("   Buffer utilization: {:.1}%", self.stats.buffer_utilization * 100.0);
        println!("   Flush count: {}", self.stats.flush_count);
        println!("   Preallocation effective: {}", self.stats.preallocation_effective);
    }
}

/// ä¾¿åˆ©å‡½æ•°ï¼šå¿«é€Ÿå†™å…¥åˆ†ç‰‡æ•°æ®
pub fn write_shards_fast<P: AsRef<Path>>(
    path: P,
    shards: &[ProcessedShard],
) -> TrackingResult<WritePerformanceStats> {
    let total_size: usize = shards.iter().map(|s| s.data.len()).sum();
    let config = HighSpeedWriterConfig {
        estimated_total_size: Some(total_size + 1024),
        ..Default::default()
    };

    let mut writer = HighSpeedBufferedWriter::new(path, config)?;
    writer.write_processed_shards(shards)
}

/// ä¾¿åˆ©å‡½æ•°ï¼šä½¿ç”¨è‡ªå®šä¹‰é…ç½®å†™å…¥
pub fn write_shards_with_config<P: AsRef<Path>>(
    path: P,
    shards: &[ProcessedShard],
    config: HighSpeedWriterConfig,
) -> TrackingResult<WritePerformanceStats> {
    let mut writer = HighSpeedBufferedWriter::new(path, config)?;
    writer.write_processed_shards(shards)
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use tempfile::NamedTempFile;

    fn create_test_shards(count: usize, size_per_shard: usize) -> Vec<ProcessedShard> {
        let mut shards = Vec::new();
        for i in 0..count {
            let data = format!("{{\"test_data_{}\": {}}}", i, i).repeat(size_per_shard / 20);
            shards.push(ProcessedShard {
                data: format!("[{}]", data).into_bytes(),
                allocation_count: 1,
                shard_index: i,
                processing_time_ms: 1,
            });
        }
        shards
    }

    #[test]
    fn test_high_speed_writer_creation() {
        let temp_file = NamedTempFile::new().unwrap();
        let config = HighSpeedWriterConfig::default();
        let writer = HighSpeedBufferedWriter::new(temp_file.path(), config);
        assert!(writer.is_ok());
    }

    #[test]
    fn test_write_processed_shards() {
        let temp_file = NamedTempFile::new().unwrap();
        let config = HighSpeedWriterConfig::default();
        let mut writer = HighSpeedBufferedWriter::new(temp_file.path(), config).unwrap();

        let shards = create_test_shards(3, 100);
        let result = writer.write_processed_shards(&shards);
        assert!(result.is_ok());

        let stats = result.unwrap();
        assert_eq!(stats.shards_written, 3);
        assert!(stats.total_bytes_written > 0);
        assert!(stats.avg_write_speed_bps > 0.0);

        // éªŒè¯æ–‡ä»¶å†…å®¹
        let content = fs::read_to_string(temp_file.path()).unwrap();
        assert!(content.starts_with("{\"allocations\":["));
        assert!(content.ends_with("]}"));
    }

    #[test]
    fn test_write_custom_json() {
        let temp_file = NamedTempFile::new().unwrap();
        let config = HighSpeedWriterConfig::default();
        let mut writer = HighSpeedBufferedWriter::new(temp_file.path(), config).unwrap();

        let json_data = b"{\"test\": \"data\"}";
        let result = writer.write_custom_json(json_data);
        assert!(result.is_ok());

        let stats = result.unwrap();
        assert_eq!(stats.total_bytes_written, json_data.len());

        // éªŒè¯æ–‡ä»¶å†…å®¹
        let content = fs::read(temp_file.path()).unwrap();
        assert_eq!(content, json_data);
    }

    #[test]
    fn test_preallocation_effectiveness() {
        let temp_file = NamedTempFile::new().unwrap();
        let shards = create_test_shards(5, 200);
        let total_size: usize = shards.iter().map(|s| s.data.len()).sum();

        // æµ‹è¯•æœ‰æ•ˆé¢„åˆ†é…
        let config = HighSpeedWriterConfig {
            estimated_total_size: Some(total_size + 1024),
            enable_monitoring: false,
            ..Default::default()
        };
        let mut writer = HighSpeedBufferedWriter::new(temp_file.path(), config).unwrap();
        let stats = writer.write_processed_shards(&shards).unwrap();
        assert!(stats.preallocation_effective);

        // æµ‹è¯•æ— æ•ˆé¢„åˆ†é…
        let temp_file2 = NamedTempFile::new().unwrap();
        let config2 = HighSpeedWriterConfig {
            estimated_total_size: Some(100), // å¤ªå°çš„é¢„åˆ†é…
            enable_monitoring: false,
            ..Default::default()
        };
        let mut writer2 = HighSpeedBufferedWriter::new(temp_file2.path(), config2).unwrap();
        let stats2 = writer2.write_processed_shards(&shards).unwrap();
        assert!(!stats2.preallocation_effective);
    }

    #[test]
    fn test_convenience_functions() {
        let temp_file = NamedTempFile::new().unwrap();
        let shards = create_test_shards(2, 150);

        // æµ‹è¯•å¿«é€Ÿå†™å…¥å‡½æ•°
        let result = write_shards_fast(temp_file.path(), &shards);
        assert!(result.is_ok());

        // æµ‹è¯•è‡ªå®šä¹‰é…ç½®å‡½æ•°
        let temp_file2 = NamedTempFile::new().unwrap();
        let config = HighSpeedWriterConfig {
            buffer_size: 1024 * 1024,
            enable_monitoring: false,
            ..Default::default()
        };
        let result2 = write_shards_with_config(temp_file2.path(), &shards, config);
        assert!(result2.is_ok());
    }

    #[test]
    fn test_flush_functionality() {
        let temp_file = NamedTempFile::new().unwrap();
        let config = HighSpeedWriterConfig {
            auto_flush: false,
            enable_monitoring: false,
            ..Default::default()
        };
        let mut writer = HighSpeedBufferedWriter::new(temp_file.path(), config).unwrap();

        let shards = create_test_shards(1, 100);
        let _stats = writer.write_processed_shards(&shards).unwrap();

        // æ‰‹åŠ¨åˆ·æ–°
        let flush_result = writer.flush();
        assert!(flush_result.is_ok());
        assert_eq!(writer.get_stats().flush_count, 1);
    }

    #[test]
    fn test_finalize() {
        let temp_file = NamedTempFile::new().unwrap();
        let config = HighSpeedWriterConfig {
            enable_monitoring: false,
            ..Default::default()
        };
        let mut writer = HighSpeedBufferedWriter::new(temp_file.path(), config).unwrap();

        let shards = create_test_shards(2, 100);
        let _stats = writer.write_processed_shards(&shards).unwrap();

        let final_stats = writer.finalize();
        assert!(final_stats.is_ok());
        
        let stats = final_stats.unwrap();
        // åœ¨å¿«é€Ÿæµ‹è¯•ä¸­ï¼Œæ—¶é—´å¯èƒ½ä¸º 0ï¼Œæ‰€ä»¥æ£€æŸ¥ >= 0
        assert!(stats.total_write_time_ms >= 0);
    }
}